# Limitations

While this collection and analysis of student critical thinking performance at the beginning and the end of semester is valuable, it is important to point out the limitations of this approach.

First, obviously, the sample is very small. To detect small effects we need large samples. The conclusion about modest improvement is further weakened by the small size of the sample. It is possible that there is no improvement and that this was just an accidental result of this group of students. 

The fact that the post survey is half the size of the pre survey is also relevant. Had they been the same size, our comparison would have been more precise. Additionally, we don't know if *exactly the same students* filled in both surveys. Completion was not mandatory, so it is quite possible that some students filled in the pre but not the post suvey, or vice versa. That produces more uncertainty about the results.

Furthermore, both students and instructors knew they were participating in this research, so it is possible that some bias squeezed through as well.

Still, the biggest limitation comes from this kind of research design. T-tests *do not uncover causality*, they are not made for that. They are good enough to make statistically significant conclusions about differences betweent the two means, and that's it. 

In other words, while we can use the t-test to see if there's difference between the two sets of data, we cannot use it to make conclusions about what produced such difference. It could be the case that something else made students slightly better at critical thinking by the end of the semester (maybe they matured in the meantime, consumed a lot of Omega 3, got bitten by a radiocative spider?), and the CRT classes made no difference. We cannot know.

## Possible extensions

I'd like to continue thinking about this topic and do more research. Besides a larger sample, I'd like to extend it by including a control group - another group of students who are not taking the critical thinking class. This would allow for making some causal claims. If we see improvement in the group taking the CRT class and we don't see comparable improvement in the group not taking the class, then perhaps we could say that teaching critical thinking makes difference.

Additionally, I would try to improve the survey, introduce more relevant questions.

## How to measure thinking?

The biggest conceptual challenge in answering the question that interested us in the beginning ('Does teaching CRT improve student thinking skills?') is the difficulty of measuring thinking outcomes. *Can critical thinking be measured at all, and if yes, how?*

Honestly, I don't know. I'd like to think that it can, and this report is my initial attempt to try doing so. Perhaps a more serious version of assessment could uncover some interesting findings. I'd also like to see more long-term effects of taking a critical thinking class in college. Do students who have taken CRT in college become better thinkers later in life?